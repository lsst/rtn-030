%Zone text from KT  https://docs.google.com/document/d/1apNSWtIpbS7aCitaF_K0JXLAAY9PvCEmmvnNvHmecdk/edit#heading=h.nwgy0freb3zv


\section{Data Management system architecture} \label{sec:dparc}
The overall system architecture is available in \citeds{LDM-148}.
Details on the \gls{USDF} specifications are given in \citeds{DMTN-189}.

\secref{sec:desc} gives a high level overview of the system. Architecturally we look
at this as a set of zones, each of which is allocated compute, storage, and networking.
As images are processed in the Prompt and Offline Production zones, their resulting data products are stored in the \gls{Archive} \gls{Zone} and made available to the \gls{DAC} \gls{Zone} where data rights holders can access and analyze them.
In addition, Rubin Observatory staff will use the Development/Integration \gls{Zone} to maintain the Observatory's \gls{software} tools and systems and to develop new versions of them.

These zones are further described here and for each a series of subsections explore :


\begin{enumerate}
\item Threats and Security infrastructure
\item Disaster recovery
\end{enumerate}

\subsection{US Data Facility}\label{sec:usdf}

A number of zones are within the \gls{USDF}.
Responsibility for the design, operations, maintenance, and security of these systems is held by the \gls{USDF} Lead at SLAC, who may delegate certain functions to the \gls{USDF} Deputy Lead, \gls{USDF} Technical Lead, other \gls{USDF} staff, S3DF staff, and SLAC IT staff.

In particular, at present the USDF Technical Lead serves as the Rubin Information Systems Security Manager for all USDF systems.

\subsubsection{Prompt Zone} \label{sec:promptenc}

The Prompt \gls{Zone} holds and processes pixel data that is subject to embargo, meaning that it is to be accessed only by Rubin and \gls{Commissioning} staff, not by the Rubin data rights community.

It receives images from the Observatory facilities in Chile via a Long Haul Network connection.
It stores these and processes them into Prompt data products of three main types:
alerts for things that have moved or changed, measurement catalogs, and processed images.
The alerts can be further subdivided into \emph{streak} alerts for objects that have moved a long distance and \emph{non-streak} alerts for all other objects.
Measurements in the catalogs follow the same subdivision. Images may be \gls{Commissioning} images used for testing and characterizing the Observatory systems, normal science images without significant \emph{streaks}, or delayed science images that do contain significant \emph{streaks}.

\emph{Streak} alerts corresponding to satellites in the \gls{CUI} catalog at \gls{SLAC} will not be released.
Uncatalogued \emph{Streak} alerts agreed with the \gls{JPL} \gls{NEO} group  are to be published at least to \gls{MPC}.
\emph{Non-streak} alerts are to be published to the world at large within 60 seconds of the original raw image being taken.
Normal science images are made available to data rights holders in the \gls{DAC} after an 80 hour embargo period.
Delayed science images, as identified by the agencies, are released after their specific embargo period. \gls{Commissioning} images are made available to data rights holders after a 30 day embargo period.

All Prompt data products are checked for quality by automated systems but also by human operators from the Rubin Observatory staff, who have access to all images and data products in order to perform spot checks or follow ups.

\paragraph{ Threats and Security infrastructure}
The obvious threat surfaces here are :
\begin{enumerate}
\item Transmission of Data from Chile. IPSec built into the routers will be used on the \gls{LHN}. \citeds{DMTN-108} discusses threats in this realm a little more.
\item Transmission to \gls{JPL}.  This transmission will only include measurements of potential NEOs, not pixel data, and will be over internet using \gls{TLS}.
\item Pipeline access for Prompt Processing. The pipelines will run on resources dedicated to the Prompt Zone and without direct external Internet connections for the duration of the processing, mitigating external, intra-node, and side channel attacks.
\item Staff access for \gls{QA}. All the usual user threats such as phishing apply - these users are however governed bu \gls{SLAC} security policies\footnote{\url{https://policies.slac.stanford.edu/} see also \url{https://it.slac.stanford.edu/cybersecurity/compliance}}.
\item QA tools. The web accessible QA tools should have a threat analysis performed by SLAC or our Security consultants although they will be behind SLAC authentication (including 2FA), Rubin authorization (via Gafaelfawr \citeds{DMTN-234}) and the S3DF HTTPS Ingress. These tools are also only accessible by staff and probably pose a low risk.
\item Physical access to storage.  For the initial 80 hours (30 days in commissioning) after acquisition the data is maintain on encrypted storage with in the physically locked Embargo rack.
\end{enumerate}

\paragraph{Disaster recovery}
All embargoed raw data is also stored on a secure server in Chile as part of the Observatory \gls{Operations} Data Service (OODS), hence it can be retransmitted as needed.
For a limited time greater than 80 hours, embargoed raw data is also available from the LSSTCam \gls{Camera} Control System, giving a third data location during the Operations embargo period.
Embargoed data products can be regenerated from the raw data.
In the case of a total wipe out of the Prompt Zone systems, use of Chef, \gls{Kubernetes}, etc. allow rapid redeployment.
See also the \gls{USDF} Disaster Recovery Plan \citeds{RTN-078}.

\subsubsection{Satellite Catalog Sub-Zone} \label{sec:satcat}
This \gls{Zone} holds the only \gls{CUI} data on the project, a catalog of satellite orbit information.
This catalog will be held on two dedicated servers (for availability) within the Embargo Rack.
Access to these servers is limited to a highly vetted list of administrators and operatorsr.

\paragraph{ Threats and Security infrastructure}
\begin{enumerate}
\item Catalog retrieval.  The catalog is downloaded from an external source via HTTPS.  Connections originate in the Sub-Zone from a dedicated server and are authenticated and authorized via a service account provided by the external source.  This minimizes access to the catalog in transit and avoids intra-node and side channel attacks on the catalog service.
\item Catalog lookup.  The catalog is held in the memory of a service that provides match/no match results for each streak measurement in a list.  The service is only accessible by S3DF systems, not the Internet.  This minimizes attacks via the service \gls{API} and prevents attacks via storage.
\end{enumerate}

\paragraph{Disaster recovery}
Since the catalog is downloaded at startup and periodically, it will be refreshed automatically after any disaster.

\subsubsection{ Offline Production Zone}

The Offline Production \gls{Zone} holds data that is not embargoed but is not yet released to the data rights community.
Access to this data is limited to Rubin staff.

Each year (or more frequently), the Offline Production Zone takes the raw images accumulated to date in the \gls{Archive} and reprocesses them to generate highly accurate, consistent images and measurement catalogs, known as a Data Release. These data products are stored in the \gls{Archive} and made available to data rights holders in the DAC after they have been checked by automated systems and after Rubin Observatory staff has vetted, characterized, and documented them. Offline Production is split between the USDF and the \gls{FrDF} and UKDF. Each Data Facility performs part of the computations and exchanges its results with the others, so all have a complete set of data products at release time.


\paragraph{ Threats and Security infrastructure}
\begin{itemize}
\item Offline production data is no longer embargoed ergo not considered under threat.  Early release of data to the data rights community or even release of small amounts of data to the world at large is more of a ``science'' problem, less a ``security'' problem.
\item Although data exchange among the facilities uses encryption (secure HTTP over \gls{TLS}), if data were to be intercepted in transfer between sites, this could only occur after the embargo period hence the security risk is low.
\item Malicious users could disrupt data or processing.
We are using standard tooling from \gls{HEP} which has been in use for many years and gives a level confidence of their suitability in this scientific endeavor.
Still internal users remain a major risk - we maintain an inclusive project and try to avoid disgruntled team members.
\end{itemize}
\paragraph{Disaster recovery}
The Offline Production systems run in batch and \gls{Kubernetes} and can be reconstituted after a disaster.
The data being processed can be regenerated from the \gls{Archive} Zone below.


\subsubsection{ \gls{Archive} Zone}
The raw images, released data products, and other records of the survey such as commands, events, and telemetry from Observatory systems are all stored in the \gls{Archive}.
As the permanent scientific record of the survey, no more than 1\% of the raw images or telemetry may be lost or corrupted according to Rubin requirements.

To help ensure this, the French Data Facility maintains a disaster recovery copy of all raw images and selected data products. Additional copies of some raw images and data products will be stored in Observatory systems in Chile.  Raw images and key data products are also stored on tape backup at \gls{SLAC}.

\paragraph{ Threats and Security infrastructure}

\begin{itemize}
\item \gls{Archive} data is no longer embargoed ergo not considered under threat.  All Archive data becomes public after the two year proprietary period, so any disclosure of small portions to the world at large is a premature release and not really a security issue.
\end{itemize}
\paragraph{Disaster recovery}
Post embargo \gls{FrDF} keeps a full copy of the raw data.

\subsubsection{Development and Integration Zone}
Rubin Observatory and \gls{USDF} staff will use this zone to build and test new versions of \gls{software} and services to be deployed in the other zone.

\paragraph{Threats and Security infrastructure}

\begin{itemize}
\item Developers have a higher level of access than data rights holders.
This is a necessary and accepted risk.
\item All developers must have SLAC accounts and therefore adhere to SLAC access rules e.g. \gls{FACTS} checking etc.
\end{itemize}

\paragraph{Disaster recovery}
SLAC keep tape backups.

All code is deployed using \gls{Kubernetes} or Chef and hence fairly easily recoverable in case of catastrophic failure.


\subsection{ \gls{USDF} \gls{DAC} Zone}
The USDF \gls{DAC} is hosted on Google and  is the responsibility of SLAC.
All deployments on the USDF DAC are made by \gls{SQuaRE} using Phalanx.

Data rights holders will use the services and systems in this zone to work with the survey data products.
It is therefore a general-purpose scientific computing facility. Generally users will interact with the Rubin \gls{Science Platform} (\gls{RSP}), which is composed of a web-based Portal Aspect providing a guided user interface for accessing and analyzing the data, a Notebook Aspect providing an interactive, flexible, programming-oriented interface, and an API Aspect providing an programmable access service.
Users of the DAC may connect from anywhere in the world over the Internet; all such users will be authenticated and authorized before accessing any \gls{RSP} service.
The \gls{RSP} is hosted on a \gls{cloud} service, currently  Google Cloud Platform.

The DAC retrieves the released data products from the \gls{Archive} Zone via protocols and services authenticated at a service account level only. While end-user identities may be included for audit and accounting purposes, fundamentally the DAC exists to provide access to all \gls{Archive} contents.

\subsubsection{ Threats and Security infrastructure}
The \gls{RSP} is  an attractive generic target due to its computing resources.
There is some user generated data which is mildly sensitive.
Hosting it on a cloud provider reduces risk considerably for the \gls{Archive} zone, and also leverages the security products and services made available by the hosting provider.
\citeds{SQR-041} provides a risk assessment for the \gls{RSP}.
\citeds{DMTN-193} provides a more in depth web risk analysis.

\begin{itemize}
\item We will have a lot of users which could be problematic. Keeping the data rights holders on the \gls{cloud} allows a clean separation of concerns between SLAC for processing and archive and the more public facing \gls{RSP}.

\item Backend archive services could provide another attack surface.  These are governed by \gls{SLAC} security.
\end{itemize}

\subsubsection{Disaster recovery}
For the software and deployed systems, all information needed to reconstitute the US DAC is stored in public repositories of container images and configuration files.

For user  spaces we rely on \gls{cloud} provider redundancy/backup/recovery.

The data in the cloud is merely a cache; a full copy is always held at the \gls{USDF} hence any Rubin data at the \gls{DAC} is expendable.

Further considerations are covered in \citeds{rtn-059}.


\subsection{ Chile \gls{DAC} Zone}
This proposed \gls{DAC} in Chile is covered in \cite{LDM-572}.
We will  start work on this in 2025 nearer the start of operations.
Chile DevOps team are responsible for the Chile \gls{DAC}.
Most applications deployed on the Chile DAC will be deployed by DM's \gls{SQuaRE} team.
The applications will be same as deployed on the USDF \gls{DAC}.

\subsubsection{ Threats and Security infrastructure}

\begin{itemize}
\item The Chile DAC is within the Recinto data center and covered by \gls{AURA}/COS security measures.\item All Rubin traffic is run through a security appliance (currently Zeek).
\item Selected Chilean users have access to the \gls{DAC}. We will keep the \gls{DAC} and the users confined with least privileges. We will use a caching mechanism analogous to the Cloud \gls{DAC} system to restrict access to the object store for the external users.
\item All access will be via \gls{RSP} pods and hence containerized - escalation potential from in side the container will be carefully monitored.
\end{itemize}
\subsubsection{Disaster recovery}
The Chile disaster recovery plan will cover the Chile \gls{DAC} \citeds{ittn-055}.



\subsection{FrDF Processing Zone}
40\% of \gls{DRP} will be done at \gls{IN2P3}.
A full back up of the raw data will also be held there.
The \gls{IN2P3} computing infrastructure is described in \url{https://doc.lsst.eu/}.
The \gls{CNRS} staff at \gls{IN2P3} are fully responsible fir the \gls{FrDF}.

\subsubsection{Threats and Security infrastructure}
The considerations for this Zone are a combination of those for the Offline Production Zone and \gls{Archive} Zone.
Access will be granted only to \gls{IN2P3} staff and Rubin staff.
IN2P3 have their own cyber security procedures which will be adhered to.
\subsubsection{Disaster recovery}
All Raw data is also at \gls{SLAC} and can be resent over a period of time.

\subsection{UKDF Processing Zone}
25\% of processing will be done on \gls{IRIS}.
\gls{ROE} staff are responsible for the \gls{UKDF} noting that \gls{IRIS} is a shared computing facility beyond their control.

\subsubsection{Threats and Security infrastructure}
The considerations for this Zone are a combination of those for the Offline Production Zone and \gls{Archive} Zone.
Access will be granted only to \gls{UKDF} staff and Rubin staff.
UKDF have their own cyber security procedures which will be adhered to.
\subsubsection{Disaster recovery}
All Raw data is at \gls{IN2P3} and can be resent over a period of time.


\subsection{External entities}
There are a number of \gls{IDAC}s which will have and serve catalogs and or images.
These are within our realm of security to some extent but not entirely - we rely on trust at some level.
\subsubsection{Threats and Security infrastructure}
The obvious threat here is unauthorized access to the data rights accessible data.
Any \gls{IDAC} must adhere to our user access protocols so this should not happen.
If unauthorized access occurs the impact is low in terms of system integrity - it may reflect badly on Rubin Observatory and erode the brand and the entire notion of restricted access to the data.

\subsubsection{Disaster recovery}
We are not concerned with disasters at IDACs.
We can resend the appropriate data to them.
